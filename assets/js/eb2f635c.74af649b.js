"use strict";(globalThis.webpackChunkai_systems_book=globalThis.webpackChunkai_systems_book||[]).push([[71],{4536:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module4/chapter3-cognitive-planning","title":"Cognitive Planning \u2014 Translating Natural Language into ROS 2 Action Sequences","description":"Introduction","source":"@site/docs/module4/chapter3-cognitive-planning.md","sourceDirName":"module4","slug":"/module4/chapter3-cognitive-planning","permalink":"/ai-system-book/module4/chapter3-cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/SyedaAnabia/ai-systems-book/docs/module4/chapter3-cognitive-planning.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Voice-to-Action \u2014 Using OpenAI Whisper for Voice Commands","permalink":"/ai-system-book/module4/chapter2-voice-to-action"},"next":{"title":"Capstone Project \u2014 The Autonomous Humanoid: Voice Command, Path Planning, Obstacle Navigation, Object Identification, and Manipulation","permalink":"/ai-system-book/module4/chapter4-capstone-autonomous-humanoid"}}');var t=i(4848),a=i(8453);const l={},r="Cognitive Planning \u2014 Translating Natural Language into ROS 2 Action Sequences",o={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"Natural Language Understanding Pipeline",id:"natural-language-understanding-pipeline",level:3},{value:"ROS 2 Action Architecture",id:"ros-2-action-architecture",level:3},{value:"Hierarchical Task Planning",id:"hierarchical-task-planning",level:3},{value:"Knowledge Representation",id:"knowledge-representation",level:3},{value:"How It Works",id:"how-it-works",level:2},{value:"Natural Language Processing Loop",id:"natural-language-processing-loop",level:3},{value:"Planning Process",id:"planning-process",level:3},{value:"ROS 2 Action Integration",id:"ros-2-action-integration",level:3},{value:"Failure Handling and Recovery",id:"failure-handling-and-recovery",level:3},{value:"Context Management",id:"context-management",level:3},{value:"Why It Matters",id:"why-it-matters",level:2},{value:"Human-Robot Collaboration",id:"human-robot-collaboration",level:3},{value:"Technical Advantages",id:"technical-advantages",level:3},{value:"Practical Applications",id:"practical-applications",level:3},{value:"Safety and Reliability",id:"safety-and-reliability",level:3},{value:"Real-World Example",id:"real-world-example",level:2},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"cognitive-planning--translating-natural-language-into-ros-2-action-sequences",children:"Cognitive Planning \u2014 Translating Natural Language into ROS 2 Action Sequences"})}),"\n",(0,t.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(e.p,{children:"Cognitive planning represents the crucial bridge between human language understanding and robotic action execution. This process involves converting natural language commands into structured sequences of ROS 2 actions that robots can execute in their environment. The challenge lies in translating human-intentioned goals into specific, executable steps while maintaining safety, efficiency, and naturalness of interaction."}),"\n",(0,t.jsx)(e.p,{children:"The cognitive planning system must account for the robot's capabilities, environmental constraints, and the inherent ambiguity of natural language. This requires sophisticated reasoning about spatial relationships, temporal sequencing, and the relationship between high-level goals and low-level actions. The system must also handle incomplete information and maintain context across multiple interactions."}),"\n",(0,t.jsx)(e.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,t.jsx)(e.h3,{id:"natural-language-understanding-pipeline",children:"Natural Language Understanding Pipeline"}),"\n",(0,t.jsx)(e.p,{children:"The cognitive planning process begins with:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Intent Recognition"}),": Identifying the underlying goal or intention from the natural language"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Entity Extraction"}),": Identifying specific objects, locations, and parameters mentioned"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action Decomposition"}),": Breaking complex commands into executable sub-tasks"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Context Integration"}),": Using environmental and situational knowledge to interpret ambiguous commands"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"ros-2-action-architecture",children:"ROS 2 Action Architecture"}),"\n",(0,t.jsx)(e.p,{children:"ROS 2 provides the action framework for:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action Servers"}),": Implementing specific robot capabilities that can be requested"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action Clients"}),": Requesting and monitoring action execution"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Feedback Mechanisms"}),": Providing status updates during action execution"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Goal Preemption"}),": Canceling or modifying actions based on new commands"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"hierarchical-task-planning",children:"Hierarchical Task Planning"}),"\n",(0,t.jsx)(e.p,{children:"Cognitive planning operates at multiple levels:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Task Level"}),': High-level goals like "clean the table" or "assist the user"']}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action Level"}),': Specific robot capabilities like "navigate to," "grasp object," or "manipulate"']}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Motion Level"}),": Low-level joint movements and trajectory execution"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Control Level"}),": Direct motor control and sensor feedback processing"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"knowledge-representation",children:"Knowledge Representation"}),"\n",(0,t.jsx)(e.p,{children:"The system maintains:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Semantic Maps"}),": Understanding of objects, locations, and affordances in the environment"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action Libraries"}),": Available robot capabilities with their preconditions and effects"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Spatial Reasoning"}),": Understanding of geometric and topological relationships"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Temporal Models"}),": Understanding of time constraints and sequential relationships"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,t.jsx)(e.h3,{id:"natural-language-processing-loop",children:"Natural Language Processing Loop"}),"\n",(0,t.jsx)(e.p,{children:"The processing pipeline operates in a continuous loop:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Language Input"}),": Receiving natural language commands from voice-to-action systems"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Semantic Parsing"}),": Converting language to structured representations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Goal Formulation"}),": Creating executable goals from parsed language"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Plan Generation"}),": Creating action sequences to achieve the goal"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Execution Monitoring"}),": Tracking plan execution and handling failures"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Context Update"}),": Updating world model based on execution outcomes"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"planning-process",children:"Planning Process"}),"\n",(0,t.jsx)(e.p,{children:"The planning process involves:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"World State Assessment"}),": Understanding the current state through sensors"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Goal Analysis"}),": Decomposing the high-level goal into sub-goals"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action Selection"}),": Choosing appropriate ROS 2 actions for each sub-goal"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sequence Optimization"}),": Ordering and scheduling actions efficiently"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Constraint Checking"}),": Verifying plans satisfy safety and environmental constraints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Plan Execution"}),": Executing action sequences through ROS 2 action clients"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"ros-2-action-integration",children:"ROS 2 Action Integration"}),"\n",(0,t.jsx)(e.p,{children:"The system interfaces with ROS 2 through:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Action Interfaces"}),": Using standard ROS 2 action interfaces for robot capabilities"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Service Calls"}),": Accessing non-action services when needed"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Topic Communication"}),": Monitoring sensor data and robot status"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Parameter Management"}),": Configuring robot behavior for specific tasks"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"failure-handling-and-recovery",children:"Failure Handling and Recovery"}),"\n",(0,t.jsx)(e.p,{children:"Robust cognitive planning includes:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Predictive Modeling"}),": Anticipating potential failures during planning"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Contingency Planning"}),": Creating alternative plans for potential failures"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Recovery Protocols"}),": Standard responses for common failure modes"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Human Interaction"}),": Requesting human assistance when autonomous recovery fails"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"context-management",children:"Context Management"}),"\n",(0,t.jsx)(e.p,{children:"The system maintains contextual information:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Spatial Context"}),": Current locations of objects and robot capabilities"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Task Context"}),": Ongoing tasks and their progress"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Interaction Context"}),": Previous commands and their outcomes"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Temporal Context"}),": Time-sensitive aspects of tasks"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"why-it-matters",children:"Why It Matters"}),"\n",(0,t.jsx)(e.h3,{id:"human-robot-collaboration",children:"Human-Robot Collaboration"}),"\n",(0,t.jsx)(e.p,{children:"Cognitive planning enables:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Natural Interaction"}),": Responding appropriately to human goals expressed in natural language"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Flexibility"}),": Handling novel situations without pre-programmed responses"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Adaptability"}),": Modifying behavior based on changing goals and environments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Predictability"}),": Acting in ways that humans can anticipate and understand"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"technical-advantages",children:"Technical Advantages"}),"\n",(0,t.jsx)(e.p,{children:"The cognitive planning approach provides:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Abstraction"}),": Shielding complex robotic behaviors behind simple natural language interfaces"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Scalability"}),": Adding new capabilities by implementing new ROS 2 actions"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Maintainability"}),": Clear separation between language understanding and action execution"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Standardization"}),": Using standard ROS 2 interfaces across different robotic platforms"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"practical-applications",children:"Practical Applications"}),"\n",(0,t.jsx)(e.p,{children:"Cognitive planning enables:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Domestic Service"}),": Robots that can handle household tasks through simple commands"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Healthcare Assistance"}),": Robots that understand patient needs and preferences"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Industrial Flexibility"}),": Robots that can adapt to changing tasks and workflows"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Educational Tools"}),": Robots that can interact naturally with students and teachers"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"safety-and-reliability",children:"Safety and Reliability"}),"\n",(0,t.jsx)(e.p,{children:"The structured approach ensures:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Controlled Execution"}),": Verifying actions are safe before execution"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Context Awareness"}),": Preventing actions that conflict with environment constraints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Error Recovery"}),": Handling failures gracefully with minimal disruption"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Human Intervention"}),": Allowing humans to override or modify plans"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"real-world-example",children:"Real-World Example"}),"\n",(0,t.jsx)(e.p,{children:"Consider a cognitive planning system for a service robot in a restaurant environment:"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Scenario"}),': A customer says, "Could you please clear the table in the corner and bring a clean tablecloth?"']}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Cognitive Planning Process"}),":"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Language Understanding"}),": The system identifies:"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Goal: Clear table and deliver tablecloth"}),"\n",(0,t.jsx)(e.li,{children:"Location: Corner table (requires spatial reasoning to identify)"}),"\n",(0,t.jsx)(e.li,{children:"Objects: Used table, clean tablecloth"}),"\n",(0,t.jsx)(e.li,{children:"Action sequence: Clearing task followed by delivery"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Planning Phase"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Robot locates the corner table using semantic mapping"}),"\n",(0,t.jsx)(e.li,{children:"Identifies objects on the table requiring clearing"}),"\n",(0,t.jsx)(e.li,{children:"Plans navigation path to the table"}),"\n",(0,t.jsx)(e.li,{children:"Determines sequence of object removal"}),"\n",(0,t.jsx)(e.li,{children:"Locates clean tablecloth in storage area"}),"\n",(0,t.jsx)(e.li,{children:"Plans path to retrieve and deliver the tablecloth"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Execution"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Navigates to corner table using Nav2"}),"\n",(0,t.jsx)(e.li,{children:"Identifies and grasps objects using perception systems"}),"\n",(0,t.jsx)(e.li,{children:"Transports objects to appropriate disposal areas"}),"\n",(0,t.jsx)(e.li,{children:"Locates and grasps clean tablecloth"}),"\n",(0,t.jsx)(e.li,{children:"Navigates back to table"}),"\n",(0,t.jsx)(e.li,{children:"Deploys tablecloth appropriately"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Monitoring and Adaptation"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"If an object is too heavy to lift, system requests human assistance"}),"\n",(0,t.jsx)(e.li,{children:"If the corner table location is ambiguous, system clarifies with customer"}),"\n",(0,t.jsx)(e.li,{children:"If a new order comes in, system reprioritizes tasks appropriately"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"ROS 2 Action Sequence"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"nav2_msgs/ComputePathToPose"})," \u2192 Navigate to corner table"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"moveit_msgs/Pickup"})," \u2192 Grasp first object to clear"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"nav2_msgs/ComputePathToPose"})," \u2192 Navigate to disposal"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"control_msgs/FollowJointTrajectory"})," \u2192 Place object in disposal"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"nav2_msgs/ComputePathToPose"})," \u2192 Return to table"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"moveit_msgs/Pickup"})," \u2192 Grasp tablecloth"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"nav2_msgs/ComputePathToPose"})," \u2192 Navigate back to table"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"control_msgs/FollowJointTrajectory"})," \u2192 Deploy tablecloth"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"std_msgs/String"})," \u2192 Publish completion status"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"This example demonstrates how cognitive planning translates a simple natural language command into a complex sequence of ROS 2 actions while handling environmental constraints and potential complications."}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"Cognitive planning represents the sophisticated process of translating natural language goals into executable ROS 2 action sequences that enable robots to perform complex tasks in human environments. This translation requires understanding of semantics, context, robot capabilities, and environmental constraints while ensuring safe and efficient operation."}),"\n",(0,t.jsx)(e.p,{children:"The integration of natural language processing with ROS 2 action architecture provides a powerful framework for creating robots that can respond intelligently to human requests. Through hierarchical planning, context management, and robust failure handling, cognitive planning systems enable more natural and intuitive human-robot interaction."}),"\n",(0,t.jsx)(e.p,{children:"As we advance toward more autonomous robotic systems, cognitive planning becomes increasingly important for enabling robots to understand and execute the complex, context-dependent requests that characterize natural human interaction. The ability to convert human goals into structured action sequences represents a crucial step toward truly collaborative human-robot teams."})]})}function h(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>l,x:()=>r});var s=i(6540);const t={},a=s.createContext(t);function l(n){const e=s.useContext(a);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:l(n.components),s.createElement(a.Provider,{value:e},n.children)}}}]);